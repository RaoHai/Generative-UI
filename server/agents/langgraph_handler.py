import asyncio
import json
import logging
from typing import AsyncIterator, Dict, Any, Union
from langchain_core.messages import BaseMessage, HumanMessage

from .models import ChatRequest, ChatResponse, StreamChunk, ChatMessage

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class LangGraphHandler:
    """LangGraph å¤„ç†å™¨ï¼Œç”¨äºæ ‡å‡†åŒ–è°ƒç”¨å’Œå“åº”å¤„ç†"""

    def __init__(self, graph):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        Args:
            graph: ç¼–è¯‘åçš„ LangGraph å®ä¾‹
        """
        self.graph = graph

    def _prepare_state(self, request: ChatRequest) -> Dict[str, Any]:
        """å‡†å¤‡ LangGraph çŠ¶æ€"""
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        messages = [msg.to_langchain_message() for msg in request.messages]

        # æ„å»ºåˆå§‹çŠ¶æ€
        state = {
            "messages": messages,
            "steps": [],
            "next_step": None
        }

        return state

    async def invoke(self, request: ChatRequest) -> ChatResponse:
        """åŒæ­¥è°ƒç”¨ LangGraph"""
        try:
            state = self._prepare_state(request)
            result = await self.graph.ainvoke(state, config=request.config or {})

            # æå–æœ€åçš„æ¶ˆæ¯å†…å®¹
            if result.get("messages"):
                last_message = result["messages"][-1]
                content = getattr(last_message, 'content', str(last_message))
            else:
                content = "No response generated"

            return ChatResponse(
                content=content,
                finish_reason="stop"
            )

        except Exception as e:
            raise Exception(f"LangGraph invocation failed: {str(e)}")

    async def stream(self, request: ChatRequest) -> AsyncIterator[str]:
        """æµå¼è°ƒç”¨ LangGraph"""
        try:
            state = self._prepare_state(request)

            # å‘é€å¼€å§‹æ ‡è®°
            start_chunk = StreamChunk(delta="ğŸš€ å¼€å§‹å¤„ç†è¯·æ±‚...\n")
            yield f"data: {start_chunk.model_dump_json()}\n\n"

            # è®°å½•è°ƒè¯•ä¿¡æ¯
            logger.info(f"å¼€å§‹æµå¼å¤„ç†ï¼Œåˆå§‹çŠ¶æ€: {list(state.keys())}")

            # ä½¿ç”¨ astream è¿›è¡Œæµå¼å¤„ç†ï¼Œè·å–æ¯ä¸ªèŠ‚ç‚¹çš„æ›´æ–°
            # stream_mode="updates" å¯ä»¥è·å–æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåçš„çŠ¶æ€å˜åŒ–
            async for chunk in self.graph.astream(state, config=request.config or {}, stream_mode="updates"):
                logger.debug(f"æ”¶åˆ°æµå¼æ›´æ–°: {chunk}")

                formatted_chunk = await self._format_stream_chunk(chunk)
                if formatted_chunk:
                    yield formatted_chunk

                # æ·»åŠ å°å»¶è¿Ÿè®©ç”¨æˆ·èƒ½çœ‹åˆ°æµå¼æ•ˆæœ
                await asyncio.sleep(0.1)

            # è·å–æœ€ç»ˆç»“æœ
            final_state = await self.graph.ainvoke(state, config=request.config or {})
            if final_state.get("messages"):
                last_message = final_state["messages"][-1]
                if hasattr(last_message, 'content') and last_message.content:
                    # å¦‚æœæœ€ç»ˆå†…å®¹æ˜¯HTMLï¼Œå‘é€é¢„è§ˆ
                    content = last_message.content
                    if content.strip().startswith('<'):
                        preview_chunk = StreamChunk(delta=f"\nğŸ“„ ç”Ÿæˆçš„HTMLæŠ¥å‘Š ({len(content)} å­—ç¬¦)\n")
                        yield f"data: {preview_chunk.model_dump_json()}\n\n"

                        # å‘é€å®Œæ•´å†…å®¹
                        content_chunk = StreamChunk(delta=content)
                        yield f"data: {content_chunk.model_dump_json()}\n\n"

            # å‘é€ç»“æŸæ ‡è®°
            final_chunk = StreamChunk(delta="\nâœ… å¤„ç†å®Œæˆ", finish_reason="stop")
            yield f"data: {final_chunk.model_dump_json()}\n\n"

        except Exception as e:
            logger.error(f"æµå¼å¤„ç†é”™è¯¯: {str(e)}")
            error_chunk = StreamChunk(delta=f"âŒ é”™è¯¯: {str(e)}", finish_reason="error")
            yield f"data: {error_chunk.model_dump_json()}\n\n"

    async def _format_stream_chunk(self, chunk: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æµå¼è¾“å‡ºå—"""
        try:
            # æ ¹æ® chunk å†…å®¹æå–æœ‰ç”¨ä¿¡æ¯
            delta_content = ""

            if isinstance(chunk, dict):
                # éå†æ¯ä¸ªèŠ‚ç‚¹çš„æ›´æ–°
                for node_name, node_data in chunk.items():
                    # å‘é€èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œçš„ä¿¡æ¯
                    delta_content += f"\nğŸ”„ æ‰§è¡ŒèŠ‚ç‚¹: {node_name}\n"

                    if isinstance(node_data, dict):
                        # å¤„ç†æ¶ˆæ¯æ›´æ–°
                        if "messages" in node_data:
                            messages = node_data["messages"]
                            if messages:
                                last_message = messages[-1]
                                if hasattr(last_message, 'content'):
                                    content = last_message.content
                                    # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨
                                    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
                                        delta_content += f"ğŸ”§ è°ƒç”¨å·¥å…·: {[tc['name'] for tc in last_message.tool_calls]}\n"
                                    # å¦‚æœæ˜¯æ™®é€šæ¶ˆæ¯å†…å®¹
                                    elif content:
                                        # æˆªå–å†…å®¹çš„ä¸€éƒ¨åˆ†è¿›è¡Œæµå¼è¾“å‡º
                                        preview = content[:200] + "..." if len(content) > 200 else content
                                        delta_content += f"ğŸ’¬ ç”Ÿæˆå†…å®¹: {preview}\n"
                                elif hasattr(last_message, 'tool_call_id'):
                                    # å·¥å…·æ‰§è¡Œç»“æœ
                                    delta_content += f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ\n"

                        # å¤„ç†æ­¥éª¤æ›´æ–°
                        if "steps" in node_data:
                            steps = node_data["steps"]
                            if steps:
                                delta_content += f"ğŸ“‹ å½“å‰æ­¥éª¤æ•°: {len(steps)}\n"

                        # å¤„ç†ä¸‹ä¸€æ­¥ä¿¡æ¯
                        if "next_step" in node_data:
                            next_step = node_data["next_step"]
                            if next_step:
                                delta_content += f"â¡ï¸ ä¸‹ä¸€æ­¥: {next_step}\n"

            if delta_content.strip():
                stream_chunk = StreamChunk(delta=delta_content)
                return f"data: {stream_chunk.model_dump_json()}\n\n"

            return None

        except Exception as e:
            error_chunk = StreamChunk(delta=f"âŒ æ ¼å¼åŒ–é”™è¯¯: {str(e)}\n")
            return f"data: {error_chunk.model_dump_json()}\n\n"